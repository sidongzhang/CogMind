import torch
import torch.nn as nn
from .attention import MultiHeadAttention
from .feed_forward import FeedForward
from .residual import PreNormResidual

class TransformerEncoderLayer(nn.Module):
    """
    Transformerç¼–ç å™¨å±‚ - å®Œæ•´çš„ç¥ç»ç½‘ç»œå±‚
    
    åŒ…å«ï¼š
    1. å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ + æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
    2. å‰é¦ˆç½‘ç»œ + æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
    
    Args:
        d_model: æ¨¡å‹ç»´åº¦
        nhead: æ³¨æ„åŠ›å¤´çš„æ•°é‡
        dim_feedforward: å‰é¦ˆç½‘ç»œä¸­é—´å±‚ç»´åº¦
        dropout: dropoutæ¯”ç‡
        activation: å‰é¦ˆç½‘ç»œæ¿€æ´»å‡½æ•°
    """
    
    def __init__(self, d_model, nhead, dim_feedforward=None, dropout=0.1, activation="relu"):
        super().__init__()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå‰é¦ˆç½‘ç»œç»´åº¦ï¼Œé»˜è®¤ä¸ºd_modelçš„4å€
        if dim_feedforward is None:
            dim_feedforward = d_model * 4
            
        self.d_model = d_model
        self.nhead = nhead
        
        # ç¬¬ä¸€ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ›
        self.self_attn = MultiHeadAttention(d_model, nhead, dropout=dropout)
        self.residual1 = PreNormResidual(d_model, dropout)
        
        # ç¬¬äºŒä¸ªå­å±‚ï¼šå‰é¦ˆç½‘ç»œ
        self.ffn = FeedForward(d_model, dim_feedforward, dropout, activation)
        self.residual2 = PreNormResidual(d_model, dropout)
        
    def forward(self, src, src_mask=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            src: æºåºåˆ— [batch_size, src_len, d_model]
            src_mask: æºåºåˆ—æ©ç  [batch_size, src_len, src_len]
            
        Returns:
            ç¼–ç åçš„åºåˆ— [batch_size, src_len, d_model]
        """
        # ç¬¬ä¸€ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ› + æ®‹å·®è¿æ¥
        def self_attn_sublayer(x):
            # è‡ªæ³¨æ„åŠ›ï¼šQ=K=V=src
            output, attn_weights = self.self_attn(x, x, x, src_mask)
            return output
            
        src = self.residual1(src, self_attn_sublayer)
        
        # ç¬¬äºŒä¸ªå­å±‚ï¼šå‰é¦ˆç½‘ç»œ + æ®‹å·®è¿æ¥
        src = self.residual2(src, self.ffn)
        
        return src


class TransformerEncoder(nn.Module):
    """
    Transformerç¼–ç å™¨ - å †å å¤šä¸ªç¼–ç å™¨å±‚
    
    Args:
        encoder_layer: ç¼–ç å™¨å±‚å®ä¾‹
        num_layers: ç¼–ç å™¨å±‚æ•°é‡
    """
    
    def __init__(self, encoder_layer, num_layers):
        super().__init__()
        self.layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])
        self.num_layers = num_layers
        
    def forward(self, src, src_mask=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            src: æºåºåˆ— [batch_size, src_len, d_model]
            src_mask: æºåºåˆ—æ©ç 
            
        Returns:
            ç¼–ç åçš„åºåˆ— [batch_size, src_len, d_model]
        """
        output = src
        
        # é€å±‚å¤„ç†
        for layer in self.layers:
            output = layer(output, src_mask)
            
        return output


def test_encoder_layer():
    """æµ‹è¯•å•ä¸ªç¼–ç å™¨å±‚"""
    print("=== æµ‹è¯•Transformerç¼–ç å™¨å±‚ ===")
    
    batch_size, src_len, d_model, nhead = 2, 5, 12, 3
    dim_ff = 48
    
    # åˆ›å»ºç¼–ç å™¨å±‚
    encoder_layer = TransformerEncoderLayer(
        d_model=d_model,
        nhead=nhead,
        dim_feedforward=dim_ff,
        dropout=0.1,
        activation="relu"
    )
    
    # åˆ›å»ºè¾“å…¥åºåˆ—
    src = torch.randn(batch_size, src_len, d_model)
    print(f"è¾“å…¥åºåˆ—å½¢çŠ¶: {src.shape}")
    
    # æµ‹è¯•æ— maskæƒ…å†µ
    output = encoder_layer(src)
    print(f"è¾“å‡ºåºåˆ—å½¢çŠ¶: {output.shape}")
    
    # éªŒè¯è¾“å…¥è¾“å‡ºå½¢çŠ¶ç›¸åŒ
    assert output.shape == src.shape, f"å½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {src.shape}"
    
    # æµ‹è¯•å¸¦maskæƒ…å†µ
    print("\n=== æµ‹è¯•å¸¦æ©ç çš„ç¼–ç å™¨å±‚ ===")
    src_mask = torch.ones(batch_size, src_len, src_len)
    src_mask[:, :, 3:] = 0  # å±è”½å2ä¸ªä½ç½®
    
    output_masked = encoder_layer(src, src_mask)
    print(f"å¸¦æ©ç è¾“å‡ºå½¢çŠ¶: {output_masked.shape}")
    
    print("âœ… ç¼–ç å™¨å±‚æµ‹è¯•é€šè¿‡!")
    return output, output_masked


def test_transformer_encoder():
    """æµ‹è¯•å®Œæ•´çš„Transformerç¼–ç å™¨ï¼ˆå¤šå±‚å †å ï¼‰"""
    print("\n=== æµ‹è¯•å®Œæ•´Transformerç¼–ç å™¨ ===")
    
    batch_size, src_len, d_model, nhead, num_layers = 2, 6, 16, 4, 3
    
    # åˆ›å»ºç¼–ç å™¨å±‚æ¨¡æ¿
    encoder_layer = TransformerEncoderLayer(
        d_model=d_model,
        nhead=nhead,
        dim_feedforward=d_model * 4,
        dropout=0.1
    )
    
    # åˆ›å»ºå¤šå±‚ç¼–ç å™¨
    encoder = TransformerEncoder(encoder_layer, num_layers)
    
    # åˆ›å»ºè¾“å…¥
    src = torch.randn(batch_size, src_len, d_model)
    print(f"è¾“å…¥å½¢çŠ¶: {src.shape}")
    print(f"ç¼–ç å™¨å±‚æ•°: {num_layers}")
    
    # å‰å‘ä¼ æ’­
    output = encoder(src)
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    # éªŒè¯å½¢çŠ¶
    assert output.shape == src.shape, f"å½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {src.shape}"
    
    print("âœ… Transformerç¼–ç å™¨æµ‹è¯•é€šè¿‡!")
    return output


if __name__ == "__main__":
    test_encoder_layer()
    test_transformer_encoder()
    print("\nğŸ‰ ç¼–ç å™¨å®ç°å®Œæˆï¼æˆ‘ä»¬å·²ç»æ„å»ºäº†å®Œæ•´çš„Transformerç¼–ç å™¨ï¼")